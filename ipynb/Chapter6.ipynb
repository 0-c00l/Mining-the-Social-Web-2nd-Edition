{
 "metadata": {
  "name": "Chapter6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Mining the Social Web, 2nd Edition\n",
      "\n",
      "##Chapter 6: Mining Mailboxes: Analyzing Who's Talking To Whom About What, How Often, and More\n",
      "\n",
      "This IPython Notebook provides an interactive way to follow along with and explore the numbered examples from [_Mining the Social Web (2nd Edition)_](http://bit.ly/135dHfs). The intent behind this notebook is to reinforce the concepts from the sample code in a fun, convenient, and effective way. This notebook assumes that you are reading along with the book and have the context of the discussion as you work through these exercises.\n",
      "\n",
      "In the somewhat unlikely event that you've somehow stumbled across this notebook outside of its context on GitHub, [you can find the full source code repository here](http://bit.ly/16kGNyb).\n",
      "\n",
      "## Copyright and Licensing\n",
      "\n",
      "You are free to use or adapt this notebook for any purpose you'd like. However, please respect the [Simplified BSD License](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/LICENSE.txt) that governs its use."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Example 1. Converting a toy mailbox to JSON**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mailbox\n",
      "import email\n",
      "import json\n",
      "\n",
      "MBOX = 'resources/ch06-mailboxes/data/northpole.mbox'\n",
      "\n",
      "# A routine that makes a ton of simplifying assumptions\n",
      "# about converting an mbox message into a Python object\n",
      "# given the nature of the northpole.mbox file in order\n",
      "# to demonstrate the basic parsing of an mbox with mail\n",
      "# utilities\n",
      "\n",
      "def objectify_message(msg):\n",
      "    \n",
      "    # Map in fields from the message\n",
      "    o_msg = dict([ (k, v) for (k,v) in msg.items() ])\n",
      "    \n",
      "    # Assume one part to the message and get its content\n",
      "    # and its content type\n",
      "    \n",
      "    part = [p for p in msg.walk()][0]\n",
      "    o_msg['contentType'] = part.get_content_type()\n",
      "    o_msg['content'] = part.get_payload()\n",
      "    \n",
      "    return o_msg\n",
      "\n",
      "# Create a mbox that can be iterated over and transform each of its\n",
      "# messages to a convenient JSON representation\n",
      "\n",
      "mbox = mailbox.UnixMailbox(open(MBOX, 'rb'), email.message_from_file)\n",
      "\n",
      "messages = []\n",
      "\n",
      "while 1:\n",
      "    msg = mbox.next()\n",
      "    \n",
      "    if msg is None: break\n",
      "        \n",
      "    messages.append(objectify_message(msg))\n",
      "    \n",
      "print json.dumps(messages, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**The following script downloads and extracts the Enron corpus to the proper working location and unarchive it**<br />\n",
      "Adapted from http://stackoverflow.com/a/22776/2292400. Alternatively, you could just download the file yourself and place it in the _ipynb/resources/ch06-mailboxes/data_ directory. The file is about 450MB so it may take a while to download. Download status displays every 5 seconds."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import urllib2\n",
      "import time\n",
      "import os\n",
      "import tarfile\n",
      "\n",
      "URL = \"http://www.cs.cmu.edu/~enron/enron_mail_20110402.tgz\"\n",
      "DOWNLOAD_DIR = \"resources/ch06-mailboxes/data\"\n",
      "\n",
      "# Downloads a file and displays a download status every 5 seconds\n",
      "\n",
      "def download(url, download_dir):    \n",
      "    file_name = url.split('/')[-1]\n",
      "    u = urllib2.urlopen(url)\n",
      "    f = open(os.path.join(download_dir, file_name), 'wb')\n",
      "    meta = u.info()\n",
      "    file_size = int(meta.getheaders(\"Content-Length\")[0])\n",
      "    print \"Downloading: %s Bytes: %s\" % (file_name, file_size)\n",
      "\n",
      "    file_size_dl = 0\n",
      "    block_sz = 8192\n",
      "    last_update = time.time()\n",
      "    while True:\n",
      "        buffer = u.read(block_sz)\n",
      "        if not buffer:\n",
      "            break\n",
      "\n",
      "        file_size_dl += len(buffer)\n",
      "        f.write(buffer)\n",
      "        download_status = r\"%10d MB  [%3.2f%%]\" % (file_size_dl / 1000000.0, file_size_dl * 100.0 / file_size)\n",
      "        download_status = download_status + chr(8)*(len(download_status)+1)\n",
      "        if time.time() - last_update > 5:\n",
      "            print download_status,\n",
      "            sys.stdout.flush()\n",
      "            last_update = time.time()\n",
      "    f.close()\n",
      "    return f.name\n",
      "\n",
      "# Extracts a gzipped tarfile. e.g. \"$ tar xzf filename.tgz\"\n",
      "\n",
      "def tar_xzf(f):\n",
      "    tar = tarfile.open(name=f, mode='r|gz')\n",
      "    tar.extractall(path='resources/ch06-mailboxes/data')\n",
      "\n",
      "f = download(URL, DOWNLOAD_DIR)\n",
      "tar_xzf(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Example 2. Converting the Enron corpus to a standardized mbox format**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import email\n",
      "from time import asctime\n",
      "import os\n",
      "import sys\n",
      "from dateutil.parser import parse # pip install python_dateutil\n",
      "\n",
      "# XXX: Download the Enron corpus to resources/ch06-mailboxes/data\n",
      "# and unarchive it there.\n",
      "\n",
      "MAILDIR = 'resources/ch06-mailboxes/data/enron_mail_20110402/' + \\\n",
      "          'enron_data/maildir' \n",
      "\n",
      "# Where to write the converted mbox\n",
      "MBOX = 'resources/ch06-mailboxes/data/enron.mbox'\n",
      "\n",
      "# Create a file handle that we'll be writing into...\n",
      "mbox = open(MBOX, 'w')\n",
      "\n",
      "# Walk the directories and process any folder named 'inbox'\n",
      "\n",
      "for (root, dirs, file_names) in os.walk(MAILDIR):\n",
      "\n",
      "    if root.split(os.sep)[-1].lower() != 'inbox':\n",
      "        continue\n",
      "\n",
      "    # Process each message in 'inbox'\n",
      "\n",
      "    for file_name in file_names:\n",
      "        file_path = os.path.join(root, file_name)\n",
      "        message_text = open(file_path).read()\n",
      "\n",
      "        # Compute fields for the From_ line in a traditional mbox message\n",
      "\n",
      "        _from = re.search(r\"From: ([^\\r]+)\", message_text).groups()[0]\n",
      "        _date = re.search(r\"Date: ([^\\r]+)\", message_text).groups()[0]\n",
      "\n",
      "        # Convert _date to the asctime representation for the From_ line\n",
      "\n",
      "        _date = asctime(parse(_date).timetuple())\n",
      "\n",
      "        msg = email.message_from_string(message_text)\n",
      "        msg.set_unixfrom('From %s %s' % (_from, _date))\n",
      "\n",
      "        mbox.write(msg.as_string(unixfrom=True) + \"\\n\\n\")\n",
      "    \n",
      "mbox.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Example 3. Converting an mbox to a JSON structure suitable for import into MongoDB**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import mailbox\n",
      "import email\n",
      "import quopri\n",
      "import json\n",
      "import time\n",
      "from BeautifulSoup import BeautifulSoup\n",
      "from dateutil.parser import parse\n",
      "\n",
      "MBOX = 'resources/ch06-mailboxes/data/enron.mbox'\n",
      "OUT_FILE = 'resources/ch06-mailboxes/data/enron.mbox.json'\n",
      "\n",
      "def cleanContent(msg):\n",
      "\n",
      "    # Decode message from \"quoted printable\" format\n",
      "\n",
      "    msg = quopri.decodestring(msg)\n",
      "\n",
      "    # Strip out HTML tags, if any are present\n",
      "\n",
      "    soup = BeautifulSoup(msg)\n",
      "    return ''.join(soup.findAll(text=True))\n",
      "\n",
      "# There's a lot of data to process, and the Pythonic way to do it is with a generator.\n",
      "# See http://wiki.python.org/moin/Generators\n",
      "# Using a generator requires a trivial encoder be passed to json for object serialization.\n",
      "\n",
      "class Encoder(json.JSONEncoder):\n",
      "    def default(self, o): return  list(o)\n",
      "\n",
      "# The generator itself...\n",
      "def gen_json_msgs(mb):\n",
      "    while 1:\n",
      "        msg = mb.next()\n",
      "        if msg is None:\n",
      "            break\n",
      "        yield jsonifyMessage(msg)\n",
      " \n",
      "def jsonifyMessage(msg):\n",
      "    json_msg = {'parts': []}\n",
      "    for (k, v) in msg.items():\n",
      "        json_msg[k] = v.decode('utf-8', 'ignore')\n",
      "\n",
      "    # The To, CC, and Bcc fields, if present, could have multiple items\n",
      "    # Note that not all of these fields are necessarily defined\n",
      "\n",
      "    for k in ['To', 'Cc', 'Bcc']:\n",
      "        if not json_msg.get(k):\n",
      "            continue\n",
      "        json_msg[k] = json_msg[k].replace('\\n', '').replace('\\t', '').replace('\\r', '')\\\n",
      "                                 .replace(' ', '').decode('utf-8', 'ignore').split(',')\n",
      "\n",
      "    try:\n",
      "        for part in msg.walk():\n",
      "            json_part = {}\n",
      "            if part.get_content_maintype() == 'multipart':\n",
      "                continue\n",
      "            json_part['contentType'] = part.get_content_type()\n",
      "            content = part.get_payload(decode=False).decode('utf-8', 'ignore')\n",
      "            json_part['content'] = cleanContent(content)\n",
      "\n",
      "            json_msg['parts'].append(json_part)\n",
      "\n",
      "        # Finally - convert the date from asctime to milliseconds since epoch using the\n",
      "        # $date descriptor so that it imports \"natively\" as an ISODate object in MongoDB\n",
      "        then = parse(json_msg['Date'])\n",
      "        millis = int(time.mktime(then.timetuple())*1000 + then.microsecond/1000)\n",
      "        json_msg['Date'] = {'$date' : millis}\n",
      "    except Exception, e:\n",
      "        sys.stderr.write('Skipping message - error encountered (%s)\\n' % (str(e), ))\n",
      "    finally:\n",
      "        return json_msg\n",
      "\n",
      "mbox = mailbox.UnixMailbox(open(MBOX, 'rb'), email.message_from_file)\n",
      "\n",
      "# Write each message out as a JSON object on a separate line\n",
      "# for easy import into MongoDB via mongoimport\n",
      "\n",
      "f = open(OUT_FILE, 'w')\n",
      "for msg in gen_json_msgs(mbox):\n",
      "    f.write(json.dumps(msg, cls=Encoder) + '\\n')\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}